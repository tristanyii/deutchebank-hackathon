from typing import Dict, TypedDict, Optional, List, Any, Annotated
from langgraph.graph import START, StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent
from langchain_core.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from langchain_groq import ChatGroq
from IPython.display import display, Image
from langchain_core.runnables.graph import MermaidDrawMethod
from dotenv import load_dotenv
from groq import Groq
import os

# load secrets
load_dotenv() 

GROQ_API_KEY = os.getenv('GROQ_API_KEY')
if not GROQ_API_KEY:
    raise ValueError("GROQ_API_KEY is not set in the environment.")

# Set up the Groq client
client = Groq(api_key = GROQ_API_KEY)

llm = "meta-llama/llama-4-scout-17b-16e-instruct"
chat_groq_llm = ChatGroq(model_name=llm, groq_api_key=GROQ_API_KEY)

# AGENT MESSAGE
research_planning_message = """
You are a Research Planning Agent. Your exclusive function is to generate a structured research plan based on a user's topic.

Mandatory Workflow:
1.  Your first and only initial action is to utilize the `extract_info` tool to analyze the user's query.
2.  Your second action is to take the direct output from the `extract_info` tool and use it as the input for the `generate_plan` tool.
Crucial Constraint Handling:
1. You MUST identify and preserve any specific constraints in the user's query, such as required source types (e.g., 'primary source documents', 'letters'), and build your entire plan around fulfilling those constraints first and foremost. If the user asks for letters, the plan must be about finding letters.
Operational Constraints:
1. The use of any tools or procedures outside of the mandatory workflow is strictly prohibited.
2. You are not permitted to conduct web searches or invoke any tools other than `extract_info` and `generate_plan`.

Required Output:
Your final response must be the complete, structured plan generated by the `generate_plan` tool.
"""

# PLANNING AGENT TOOLS 
@tool
def extract_info(query: str):
    """
    Understands the user's input/query and breaks it down into the historical topic and time period, returning.

    Parameters:
        str: The user's historical query.

    Returns:
        str: A formatted string containing the extracted information.
    """
    # Use the LLM to extract the historical topic and time period from the query
    # Instruct the LLM to format the output as a simple string
    prompt = f"""
    From the following historical research query, extract the main historical topic, the specific time period, location, and group of people involved.
    If a value is not present in the query, use the general value linked to the topic.

    Query: {query}

    Format the output as a single string like this:
    Topic: [Extracted Topic] | Time Period: [Extracted Time Period] | Location: [Extracted Location] | Group of People involved: [Extracted Group of People]
    """
    response = chat_groq_llm.invoke(prompt)
    return response.content


@tool
def generate_plan(info_string: str):
    """
    Takes a formatted string from extract_info to plan the research.

    Args:
        str: Expected format: "Topic: [...] | Time Period: [...] | Location: [...] | Group of People involved: [...]"

    Returns:
        str: A structured research plan based on the extracted information.
    """
    # Parse the information from the formatted string
    info = {}
    for part in info_string.split(" | "):
        if ":" in part:
            key, value = part.split(":", 1)
            info[key.strip()] = value.strip()

    # Get the extracted information, defaulting to "N/A" if parsing fails or key is missing
    topic = info.get("Topic", "N/A")
    time_period = info.get("Time Period", "N/A")
    location = info.get("Location", "N/A")
    group_involved = info.get("Group of People involved", "N/A")

    # Use the LLM to generate a research plan based on the extracted information
    prompt = f"""
    Based on the following historical information:

    Topic: {topic}
    Time Period: {time_period}
    Location: {location}
    Group of People involved: {group_involved}

    Create a plan that includes:
    - Five specific research questions to answer based on the topic, time period, location, and group involved.
    - Ten suggested keywords for searching the historical topic
    -  and search strategies.

    Format the output like this:
    Research Questions:
      questuion1
      question2
      question3
      question4
      question5

    Suggested Keywords:
      keyword1
      keyword2
      keyword3
      keyword4
      keyword5
      keyword6
      keyword7
      keyword8
      keyword9
      keyword10
    """

    response = chat_groq_llm.invoke(prompt)
    return response.content

# Agent Class 
class Research_Planning_Agent():
    def __init__(self): 
        self.model = chat_groq_llm
        self.tools = [extract_info, generate_plan]
        self.prompt = research_planning_message
        self.inner_message : str = None
        self.research_planning_agent = create_react_agent(
            model=self.model,
            tools=self.tools,
            prompt=self.prompt,
            name="research_planning_agent"
        )

    def visualize_graph(self):
        return display(Image(self.research_planning_agent.get_graph().draw_mermaid_png()))
    

    def show_inner_workings(self): 
        return getattr(self, 'inner_message', [])


    def run(self, query: str): 
        response = self.research_planning_agent.invoke({"messages": [{"role": "user", "content": query}]})
        self.inner_message = response['messages']
        
        return response['messages'][-2].content
